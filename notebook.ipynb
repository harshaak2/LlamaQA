{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "MODEL = \"llama3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Ollama(model=MODEL)\n",
    "embeddings = OllamaEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why couldn't the bicycle stand up by itself?\n",
      "\n",
      "Because it was two-tired!\n",
      "\n",
      "(Sorry, I know it's a bit of a \"dad\" joke, but I hope it brought a smile to your face!)\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(\"Tell me a joke\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhy couldn't the bicycle stand up by itself?\\n\\n(wait for it...)\\n\\nBecause it was two-tired!\\n\\nHope that made you smile! Do you want to hear another one?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# pipe the model output as an input to the parser using chain\n",
    "chain = model | parser  # define the chain\n",
    "chain.invoke(\"Tell me a joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='2DP-FHS: 2D Pareto Optimi zed Fog Head Selection for  \\nMultiple  EEG H ealthcare  Data Analysis and \\nComputations  \\nSri Harsha Kurra1, Rama Krushna Rath1, Sreeja S. R.1 \\n \\n1 Indian Institute of Information Technology Sri City,  \\nChittoor, Andhra Pradesh, India  \\n \\nAbstra ct. In recent years, the increase in heal thcare data  demands the  adoption  \\nof fog computing for  fast processing and analysis of large data volumes. Fog \\ncomputing enables  real-time data computations that serves closely to healthcare \\ndevices. This study propo ses the analysis and computations of EEG healthcare \\ndata using Pareto optimization -based fog computing. The proposed 2DP -FHS \\ntechnique selects a fog head among heterogeneous fog devices to manage  the \\nEEG data within the fog layer. Additionally, an alternat ive fog head is \\ndesignated to ensure continuous operation within the fog layer . The study  \\nconsider s various  scenarios and unbiased fog devices in the  simulation. Further,  \\nit presents  the delay analysis varying  the number of EEG and fog devices. The \\nresults  show the effectiveness of the proposed technique across  all scenarios.     \\nKeywords : Pareto  optimization, fog head selection, EEG healthcare, delay \\nanalysis, fog computing . \\n1   Introduction  \\nThe rapid growth in healthcare data necessitates  the need for tec hnological \\nadvancements in  real-time computation and analysis.  Healthcare data  that provide s \\ncrucial insights into human physiological conditions  are time -sensitive. \\nElectroencephalogram (EEG)  signal  is one of the important healthcare data that gives \\nvast medical  information about  human brain conditions  [1]. Moreover, the EEG \\nsensors generate continuous signal s and a large  volume of sensitive data. Analyzing \\nEEG healthcare data is vital for clinical decisions and epidemiological research . \\nTherefore, the ado ption of fog computing is vital  for efficient EEG data computation, \\nfaster decision -making, and minimizing latency. Fog computing is an extension of \\ncloud computing that provides  lightweight processing , real -time data analysis , and a \\nlimited storage capaci ty [2], [3]. The fog devices are  also capable of handling EEG \\ndata generated from multi -channel EEG devices  [4].   \\nMoreover, the fog computing  architecture is useful for minimizing  the delay  and \\nenergy  and cost  using various optimization techniques. Paper  [5] proposes  a deep \\nlearning -based  optimization technique for  resource scheduling management in fog', metadata={'source': 'fog_computing_paper.pdf', 'page': 0}),\n",
       " Document(page_content='computing focusing on minimizing delay and bandwidth.  Paper [6] uses FireFly \\noptimization for cost -reduction -based resource allocation and load balancing in  cloud \\nfog architecture.  Further, multiple heterogeneous fog devices participate in parallel \\nand distributed decision -making processes. Therefore, the optimal selection of fog \\nheads and fog resources is necessary  [7], [8], [9] . Many techniques are develope d by \\nthe researchers emphasizing the optimal selection methods for various applications, \\nbut there is a lack of developments in EEG healthcare systems. In this work, the \\nauthors have focused on the optimal fog head selection technique for EEG based \\nhealthc are systems using the Pareto Optimization [10].  \\n1.1   Motivation  and Contribution  \\nThe existing EEG healthcare systems are mostly cloud -dependent  [11]. The cloud \\nprovides major  services such as big data management, permanent storage , and heavy  \\nprocessing; b ut consumes high bandwidth and high latency which is unacceptable in \\nreal-time healthcare analysis  [12], [13] . Moreover, EEG devices are single -user \\nassistive devices  and, therefore need dedicated computing resources. To address the \\nabove challenges, fog c omputing is integrated with multiple EEG healthcare systems. \\nThe integration of fog computing supports real -time data analysis with minimum \\nlatency and faster response time  [14], [15] . Further, it supports scalability and \\nheterogeneity which helps in proce ssing huge volumes of EEG data in a distributed \\nmanner  [16]. The contributions in this paper are listed below:  \\ni) A two -layer architecture is proposed, where multiple EEG devices are merged in \\none platform to perform distributed computation and data analyt ics connecting with a \\ngroup of heterogeneous fog devices . \\nii) An optimal  Fog Head  (FH) and an Alternate Fog Head (AFH) are selected using \\ntwo-dimensional  Pareto  optimization undertaking multiple scenarios.  \\niii) Further delay analysis is performed in the fo g layer with a change in the number of \\nEEG devices and the number of fog devices.  \\n   The further sections are organized as follows: Section 2 describes the proposed \\nmethodology. Section 3 illustrates the simulation result. Finally, section 4 concludes \\nthe paper.  \\n2   Proposed Methodology  \\nIn this paper, the authors have proposed a multi -layer architecture where multiple \\nEEG devices collaborate with multiple fog devices through a fog head. In the real \\nscenario, a single fog device is not sufficient for process ing EEG data from multiple \\nEEG devices due to energy, storage , and computational constraints. Therefore, \\nmultiple fog devices having different configurations are considered for this work. \\nAlso, in this work, an optimal fog device among all the fog devices is selected which \\nis discussed further. The next subsection presents the proposed architectural view and \\nits functions.', metadata={'source': 'fog_computing_paper.pdf', 'page': 1}),\n",
       " Document(page_content='2.1   Architectural View   \\nThe proposed architecture consists of two layers: a device layer and a fog layer; as \\nshown in Fig.  1. The devi ce layer consists of multiple EEG devices which are \\nindependent of each other. In the fog layer, heterogeneous fog devices are connected \\nto the FH.   \\nThe functions  of the device layer are  to: \\n\\uf0b7 Sense  brain signals  of patients using multiple EEG sensors  \\n\\uf0b7 Divide  the continuous raw EEG signal into chunks  \\n\\uf0b7 Transmit  the chunks as output files to the fog layer  \\nThe functions  of the fog layer are  to: \\n\\uf0b7 Receive the EEG data files from the device layer  \\n\\uf0b7 Select  one of the fog devices as FH  \\n\\uf0b7 Collaborative and distributed proces sing of the tasks among fog devices  \\n\\uf0b7 Acknowledge  the resp onses  \\n \\n                   \\n  \\nFig. 1. Proposed  2DP-FHS architecture .', metadata={'source': 'fog_computing_paper.pdf', 'page': 2}),\n",
       " Document(page_content='2.2   Fog Head Selection  \\nThe necessity of selecting a FH is to collect the EEG files from the device layer and \\ndistribute the tasks among fog devices. Also, the additional responsibility of the FH is \\nto collect the responses generated by the fog devices and to provide access to the end \\nusers. This section  describes the mathematical modeling of fog parameters and the \\nworkflow of the proposed technique.   \\n2.2.1   Mathematical Modeling  \\n \\nIn this work, the selection of FH is done by using two parameter index values: (i) Fog \\nDelay Index (FDI) and (ii) Fog Performance Index (FPI).  \\n \\nTheorem 1:  The Fog Delay Index (\\n ) of \\n  fog device is the ratio between the \\nsum of Propagation Delay (\\n ), Processing Delay (\\n ), and Average Queuing \\nDelay (\\n ) to the Total Network Delay (\\n ). \\n \\nProof : \\n \\nDefinition 1:  The propagation de lay is the ratio between the summation of \\n  , \\n and the velocity of signal (SS) in wireless medium.  \\n \\nFor a set of M number of EEG devices and N number of fog devices, the propagation \\ndelay of \\n fog device is calculated as : \\n \\n .    (1) \\n.  (2) \\n \\nWhere, (\\n  , \\n) is the coordinate of \\n  fog device and (\\n  , \\n), (\\n  , \\n) are the \\ncoordinates of \\n EEG and \\n  fog device respectively.  \\n \\nThe processing delay of a fog device primarily depends on the clock speed of the fog \\nprocessor. It is the total time taken to complete the assigned tasks and calculated as \\nfollows:  \\n  .    (3)', metadata={'source': 'fog_computing_paper.pdf', 'page': 3}),\n",
       " Document(page_content='Where, \\n denotes the volume of EEG data assigned to \\n  fog device and \\n denotes the average clock speed.  \\n \\nThe Average Queuing Delay (\\n ) of \\n  fog device is calculated as the average \\nwaiting time of a task in the buffer.  \\n \\n  .  (4) \\n \\nWhere n is total number of tasks, \\n  is the buffer waiting time of \\n  task and \\n, \\n, ‚Ä¶ , \\n  \\n \\n \\n \\nDefinition 2:  The Buffer Waiting Time (\\n ) of \\n  task i s the summation of \\nprocessing time of  n-1 tasks.  \\n \\n .  (5) \\n \\nWhere \\n is the processing time of \\n  task assigned to \\n  fog device and \\n \\n \\nFinally, the Total Delay \\n  of \\n  fog device is shown in Eq. 6. \\n \\n .  (6) \\n \\nFurther, \\n  is the network delay which is calculated as the sum of total delay of all  \\nthe fog devices.  \\n \\n  .    (7) \\n \\nFrom Eq. 6 and Eq.  7, we have the fog delay index as  \\n \\n  .  (8) \\n \\nTheorem 2:  The Fog Performance Index \\n  of \\n  fog device is defined as the \\nweighted summation of Idle Physical Memory  \\n  and Computational \\nEfficiency\\n . \\n \\nProof:', metadata={'source': 'fog_computing_paper.pdf', 'page': 4}),\n",
       " Document(page_content='The performance of a fog device is generally dependent on its RAM and the processor \\ncomponen ts such as clock speed (C), Million Instructions Per Second (MIPS). The \\n of \\n  fog device is calculated as:  \\n \\n  .   (9) \\n \\nThe computational efficiency of \\n  fog device is directly proportional to the MIPS \\nand reciprocal of  its clock speed. For the fog device having a minimum clock speed of  \\n and a maximum clock speed of \\n , the average clock speed is calculated as  \\n \\n   .   (10) \\n \\nConsequently, \\n  is calculated as  \\n \\n   .    (11) \\n \\nLet, \\n  be the relative weight of \\n  and \\n  be the relative weight of \\n . The \\n  is \\nsummed from Eq. 10 and Eq. 11 as \\n \\n   .  (12) \\n \\nWhere,  \\n . This indicates the equal weightage of \\n  and \\n  in \\ncalculating \\n . \\n \\n2.2.2   Workflow  \\n \\nThe workflow of the FH selection is given in Fig. 2 . The aim is to select an optimal \\nFH for the smooth operation of EEG tasks in the fog layer. Also, to ensure the \\nuninterrupted operat ion in the fog layer, an additional fog device, called as Alternate \\nFog Head (AFH), is also chosen; which takes control of the FH in case of failure.', metadata={'source': 'fog_computing_paper.pdf', 'page': 5}),\n",
       " Document(page_content='Fig. 2. Workflow diagram of the proposed 2DP -FHS technique.  \\n \\n   The selection  process  of FH and AFH i s described below:  \\nStep 1:  Each fog device is given inputs to calculate two values:  FDI and FPI as given \\nin Eq. 8 and Eq. 12.  \\nStep 2:  Multiobjective Pareto  optimization  is applied  to separate Dominated Solution \\nSpace (DSS) and Non -dominated Solution Space  (NSS). The solutions which have \\nworse resultant values for either FDI or FPI compared to at least one solution in the \\nsolution space is called DSS. Similarly, NSS is the set of solutions that dominate at \\nleast one solution for both FDI and FPI. The NSS is  generated based on the number of \\nfog devices and their configurations.  \\nStep 3 : If NSS is present, then two Reference P oints  (RP)  are selected  as described . \\nThe first point is the least FDI and the second point is the most FPI among NSS . Next, \\na Utopia Po int (UP) is calculated which is the  intersection of  two extreme values in \\nNSS.  \\nStep 4:  If NSS is not present, then a tradeoff function, denoted by \\n , is \\ncalculated for each fog device which is the weighted sum of the normalized FDI and \\nFPI values. Where \\n  is the relative weight of FDI and \\n  is the relative weight of FPI.   \\nStep 5:  Based on the number of non -dominated sol utions in the NSS, there are three  \\ncases  listed below.  \\nCase  I: If one n on-dominated solution occurs , then that is selected as the FH, and \\nAFH is selected as described in Step 4 .', metadata={'source': 'fog_computing_paper.pdf', 'page': 6}),\n",
       " Document(page_content='Case  II: If NSS consists of more than one non -dominated solution , then FH and the \\nAFH are selected based on the minimal distances from UP.  \\nCase III: For the chosen \\n  and \\n  values, there are  3 sub -cases  as listed below:  \\n\\uf0b7 If \\n , solution impact: Delay Minimized  \\n\\uf0b7 If \\n , solution impact: Performance Maximized  \\n\\uf0b7 If \\n , solution impact: Balanced  \\n3   Simulation and Result Analysis  \\nThe simulation  work  is carried out using Python v3.12 in MAC OS; having M1 Pro \\nprocessor and 16 GB RAM  assuming the EEG and the fog layer as 200m √ó 200m \\narea. Moreover , a synthetic fog database is created with 8  distinct  fog devices as given \\nin the Table 1. Further, Table 2 describes the synthetic EEG data generated for \\nprocessing and analysis.  \\n \\nTable 1.  Heterogeneous f og devices with  their configurations . \\n \\nFog ID \\n  (in GHz)  \\n  (in GHz)  RAM  (in GB)  MIPS  \\n1 1.43 1.43 4 9000  \\n2 1.5 1.5 4 12000  \\n3 1.4 1.9 8 9000  \\n4 1.1 2.6 4 8800  \\n5 1.8 2.84 8 12000  \\n6 1.8 3.23 6 15000  \\n7 2.5 3.4 4 20000  \\n8 2.6 3.8 8 12080  \\n \\n Table 2.  Synthetic EEG dataset . \\n \\nEEG No.  Channels  Sampling F requency  Files Data Volume  \\n1 32 150 Hz  10 6.9945 Mb  \\n2 16 170 Hz  4 5.24 Mb  \\n3 64 250 Hz  6 15.42 Mb  \\n4 32 230 Hz  5 7.95 Mb  \\n \\n   Further, in this section, th e authors have illustrated two different scenarios in \\nselecting FH and AFH  for NSS . Fig. 3 shows the placement of the devices with the \\npareto solutions where UP is different from RP. However, Fig. 4 shows a different \\nscenario where UP is same as RPs.', metadata={'source': 'fog_computing_paper.pdf', 'page': 7}),\n",
       " Document(page_content='(a)                          (b) \\n \\nFig. 3.  (a) Selection of FH (Fog 2) and AFH (Fog 1) for scenario -1, (b) UP is \\ndifferent from RPs  \\n \\n \\n \\n       \\n  \\n        (a)                          (b) \\n \\nFig. 4. (a) Selection of FH (Fog 6) and AFH (Fog 3) for scena rio-2, (b) UP and A Ps \\nare same  \\n \\n   Furthermore, the selection of FH and AFH is shown in Table 4 corresponding to \\nTable 3; where the fitness score is based on the tradeoff between FDI and FPI. The \\ntradeoff function is calculated in Eq. 13 as follows.  \\n    .                           (13)', metadata={'source': 'fog_computing_paper.pdf', 'page': 8}),\n",
       " Document(page_content='Table 3.  Synthetic fog dataset without non -dominated solution space.  \\nFog ID FDI  FPI Fog ID  FDI FPI \\n1 0.4321  2.3232  5 0.6232  3.9272  \\n2 0.5444  2.4444  6 0.1734  2.1111  \\n3 0.8818  4.8734  7 0.1678  2.0676  \\n4 0.5594  3.1212  8 0.8716 4.0256  \\nTable 4.  Selection of FH and AFH with variable weights  \\nùù∞ ùû´ FH AFH  \\n1 0 7 6 \\n0.9 0.1 7 6 \\n0.8 0.2 6 7 \\n0.7 0.3 1 2 \\n0.6 0.4 2 4 \\n0.5 0.5 2 4 \\n0.4 0.6 4 2 \\n0.3 0.7 5 8 \\n0.2 0.8 8 5 \\n0.1 0.9 3 8 \\n0 1 3 8 \\n \\nFig. 5.  The average delay analysis wit h increase in number of EEG devices and fog \\ndevices .', metadata={'source': 'fog_computing_paper.pdf', 'page': 9}),\n",
       " Document(page_content='In this work, the authors have emphasized the delay analysis with change in number \\nof EEGs and fog devices. The result shown in Fig. 5 is generated from the average of \\n100 iterations. The graph represent s the increase in average delay while increasing \\nworkloads and further decreasing with an increase in fog devices.  \\n4   Conclusion  \\nIn this paper, the optimized fog head selection technique is discussed for EEG \\nhealthcare systems. Various factors such as di stance, processor, number of devices, \\netc. are affecting in selection of optimal FH. The authors have considered all possible \\nscenarios and unbiased fog characteristics to enhance the effectiveness of the 2DP -\\nFHS technique. Additionally the results highlig ht the significance of this approach \\nwhich works fine for heterogeneous fog devices and multiple EEG devices. In the \\nfuture work, the authors have aimed to include more parameters considering energy \\nand storage to select optimal fog devices.      \\nReference s \\n1. N. S. Amer and S. B. Belhaouari, \"EEG Signal Processing for Medical Diagnosis, \\nHealthcare, and Monitoring: A Comprehensive Review,\" in  IEEE Acces s, vol. 11, pp. \\n(2023) 143116 -14314 2 \\n2.  Resul Das, Muhammad Muhammad Inuwa, A review on fog computing: Issues, \\ncharacteristics, challenges, and potential applications, Telematics and  Informatics \\nReports, Volume 10 , 100049, ISSN 2772 -5030 (2023 ) \\n3. de Moura Costa, H.J., da Costa, C.A., da Rosa R ighi, R.  et al. Fog computing in \\nhealth: A systematic literature review.  Health Technol . 10, (2020) 1025 ‚Äì1044 \\n4. A. K. Idrees, S. K. Idrees, R. Couturier and T. Ali -Yahiya, \"An Edge -Fog \\nComputing -Enabled Lossless EEG Data Compression With Epileptic Seizure  \\nDetection in IoMT Networks,\" in  IEEE Internet of Things Journa l, vol. 9, no. 15, \\n(2022) pp. 13327 -13337  \\n5. N. Alshammari, H. Pervaiz, H. Ahmed and Q. Ni, \"Delay and Total Network Usage \\nOptimisation Using GGCN in Fog Computing,\"  2023 IEEE 34th Annual Inte rnational \\nSymposium on Personal, Indoor and Mobile Radio Communications (PIMRC ), \\nToronto, ON, Canada, (2023), pp. 1 -6 \\n6. Hassan, K., Javaid, N., Zafar, F., Rehman, S., Zahid, M., Rasheed, S. A Cloud Fog \\nBased Framework for Efficient Resource Allocation Usi ng Firefly Algo rithm. In: \\nBarolli, L., Leu, FY , Enokido, T., Chen, HC. (eds) Advances on Broadband and \\nWireless Computing, Communication and Applications. BWCCA 2018. Lecture \\nNotes on Data Engineering and Communications Technologies, vol 25. Springer, \\nCham. (2019 ) \\n7. Sunday Oyinlola Ogundoyin, Ismaila Adeniyi Kamil, Optimal fog node selection \\nbased on hybrid particle swarm optimization and firefly algorithm in dynamic fog', metadata={'source': 'fog_computing_paper.pdf', 'page': 10}),\n",
       " Document(page_content='computing services, Engineering Applications of Artificial Intelligence, Volume 121, \\n105998, (2023) ISSN 0952 -1976 \\n8. Tao Han, Lijuan Zhang, Sandeep Pirbhulal, Wanqing Wu, Victor Hugo C. de \\nAlbuquerque, A novel cluster head selection technique for edge -computing based \\nIoMT systems, Computer Networks, Volume 158, (2019), Pages 114 -122, ISSN  \\n1389 -1286 \\n9. Devi, A., Kait, R., Ranga, V. Automated Cluster Head Selection in Fog -VANET \\nVia Machine Learning. In: Sharma, H., Shrivastava, V., Kumari Bharti, K., Wang, L. \\n(eds) Commun ication and Intelligent Systems . Lecture Notes in Networks and \\nSystems , vol 461. Springer, Singapore (2022 ) \\n10. Nyoman Gunantara | A review of multi -objective optimization: Methods and its \\napplications, Cogent Engineering, 5:1, (2018) 1502242  \\n11. X. Gu  et al., \"EEG -Based Brain -Computer Interfaces (BCIs): A Survey of Recent \\nStudies on Signal Sensing Technologies and Computational Intelligence Approaches \\nand Their Applications,\" in  IEEE/ACM Transactions on Computational Biology and \\nBioinformatic s, vol. 18, no. 5, (2021) pp.1645 -1666   \\n12. Dilip Kumar Sharma, Dhruva Sreenivasa C hakravarthi, Asmat Ara Shaikh, Alim \\nAl Ayub Ahmed, Sushma Jaiswal, Mohd Naved, The aspect of vast data management \\nproblem in healthcare sector and implementation of cloud computing technique, \\nMaterials Today: Proceedings, Volume 80, Part 3, (2023), Pages 3 805-3810, ISSN \\n2214 -7853  \\n13. Anjum, A.  et al. Big Data Analytics in Healthcare: A Cloud -Based Framework for \\nGenerating Insights. In: Antonopoulos, N., Gillam, L. (eds) Cloud Computing. \\nComputer Communications and Networks. Springer, Cham (2017 ) \\n14. Jain, R., Gupta, M., Nayyar, A., Sharma, N. Adoption of Fog Computing in \\nHealthcare 4.0. In: Tanwar, S. (eds) Fog Computing for Healthcare 4.0 Environments. \\nSignals and Communication Technology. Springer, Cham (2021 ) \\n15. Dubey, H.  et al. Fog Computing in Medical Internet -of-Things: Architecture, \\nImplementation, and Applications. In: Khan, S., Zomaya, A., Abbas, A. (eds) \\nHandbook of Large -Scale Distributed Computing in Smart Healthcare. Scalable \\nComputing and Communications. Springer, Cham (2017 ) \\n16. N. M. Gonzalez  et al., \"Fog computing: Data analytics and cloud distributed \\nprocessing on the network edges,\"  2016 35th International Conference of the Chilean \\nComputer Science Society (SCCC ), Valparaiso, Chile, (2016), pp. 1 -9.', metadata={'source': 'fog_computing_paper.pdf', 'page': 11})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"fog_computing_paper.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer the question based on the context below. If you can't answer the question, reply with \"I don't know\".\n",
      "Context: Here is some context\n",
      "Question: Here is a question\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't answer the question, reply with \"I don't know\".\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# building up the prompt using the template\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "print(prompt.format(context=\"Here is some context\", question=\"Here is a question\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'OllamaInput',\n",
       " 'anyOf': [{'type': 'string'},\n",
       "  {'$ref': '#/definitions/StringPromptValue'},\n",
       "  {'$ref': '#/definitions/ChatPromptValueConcrete'},\n",
       "  {'type': 'array',\n",
       "   'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "     {'$ref': '#/definitions/HumanMessage'},\n",
       "     {'$ref': '#/definitions/ChatMessage'},\n",
       "     {'$ref': '#/definitions/SystemMessage'},\n",
       "     {'$ref': '#/definitions/FunctionMessage'},\n",
       "     {'$ref': '#/definitions/ToolMessage'}]}}],\n",
       " 'definitions': {'StringPromptValue': {'title': 'StringPromptValue',\n",
       "   'description': 'String prompt value.',\n",
       "   'type': 'object',\n",
       "   'properties': {'text': {'title': 'Text', 'type': 'string'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'StringPromptValue',\n",
       "     'enum': ['StringPromptValue'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['text']},\n",
       "  'ToolCall': {'title': 'ToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'object'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id']},\n",
       "  'InvalidToolCall': {'title': 'InvalidToolCall',\n",
       "   'type': 'object',\n",
       "   'properties': {'name': {'title': 'Name', 'type': 'string'},\n",
       "    'args': {'title': 'Args', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'error': {'title': 'Error', 'type': 'string'}},\n",
       "   'required': ['name', 'args', 'id', 'error']},\n",
       "  'UsageMetadata': {'title': 'UsageMetadata',\n",
       "   'type': 'object',\n",
       "   'properties': {'input_tokens': {'title': 'Input Tokens', 'type': 'integer'},\n",
       "    'output_tokens': {'title': 'Output Tokens', 'type': 'integer'},\n",
       "    'total_tokens': {'title': 'Total Tokens', 'type': 'integer'}},\n",
       "   'required': ['input_tokens', 'output_tokens', 'total_tokens']},\n",
       "  'AIMessage': {'title': 'AIMessage',\n",
       "   'description': 'Message from an AI.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ai',\n",
       "     'enum': ['ai'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'},\n",
       "    'tool_calls': {'title': 'Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/ToolCall'}},\n",
       "    'invalid_tool_calls': {'title': 'Invalid Tool Calls',\n",
       "     'default': [],\n",
       "     'type': 'array',\n",
       "     'items': {'$ref': '#/definitions/InvalidToolCall'}},\n",
       "    'usage_metadata': {'$ref': '#/definitions/UsageMetadata'}},\n",
       "   'required': ['content']},\n",
       "  'HumanMessage': {'title': 'HumanMessage',\n",
       "   'description': 'Message from a human.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'human',\n",
       "     'enum': ['human'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'example': {'title': 'Example', 'default': False, 'type': 'boolean'}},\n",
       "   'required': ['content']},\n",
       "  'ChatMessage': {'title': 'ChatMessage',\n",
       "   'description': 'Message that can be assigned an arbitrary speaker (i.e. role).',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'chat',\n",
       "     'enum': ['chat'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'role': {'title': 'Role', 'type': 'string'}},\n",
       "   'required': ['content', 'role']},\n",
       "  'SystemMessage': {'title': 'SystemMessage',\n",
       "   'description': 'Message for priming AI behavior, usually passed in as the first of a sequence\\nof input messages.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'system',\n",
       "     'enum': ['system'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content']},\n",
       "  'FunctionMessage': {'title': 'FunctionMessage',\n",
       "   'description': 'Message for passing the result of executing a function back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'function',\n",
       "     'enum': ['function'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'}},\n",
       "   'required': ['content', 'name']},\n",
       "  'ToolMessage': {'title': 'ToolMessage',\n",
       "   'description': 'Message for passing the result of executing a tool back to a model.',\n",
       "   'type': 'object',\n",
       "   'properties': {'content': {'title': 'Content',\n",
       "     'anyOf': [{'type': 'string'},\n",
       "      {'type': 'array',\n",
       "       'items': {'anyOf': [{'type': 'string'}, {'type': 'object'}]}}]},\n",
       "    'additional_kwargs': {'title': 'Additional Kwargs', 'type': 'object'},\n",
       "    'response_metadata': {'title': 'Response Metadata', 'type': 'object'},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'tool',\n",
       "     'enum': ['tool'],\n",
       "     'type': 'string'},\n",
       "    'name': {'title': 'Name', 'type': 'string'},\n",
       "    'id': {'title': 'Id', 'type': 'string'},\n",
       "    'tool_call_id': {'title': 'Tool Call Id', 'type': 'string'}},\n",
       "   'required': ['content', 'tool_call_id']},\n",
       "  'ChatPromptValueConcrete': {'title': 'ChatPromptValueConcrete',\n",
       "   'description': 'Chat prompt value which explicitly lists out the message types it accepts.\\nFor use in external schemas.',\n",
       "   'type': 'object',\n",
       "   'properties': {'messages': {'title': 'Messages',\n",
       "     'type': 'array',\n",
       "     'items': {'anyOf': [{'$ref': '#/definitions/AIMessage'},\n",
       "       {'$ref': '#/definitions/HumanMessage'},\n",
       "       {'$ref': '#/definitions/ChatMessage'},\n",
       "       {'$ref': '#/definitions/SystemMessage'},\n",
       "       {'$ref': '#/definitions/FunctionMessage'},\n",
       "       {'$ref': '#/definitions/ToolMessage'}]}},\n",
       "    'type': {'title': 'Type',\n",
       "     'default': 'ChatPromptValueConcrete',\n",
       "     'enum': ['ChatPromptValueConcrete'],\n",
       "     'type': 'string'}},\n",
       "   'required': ['messages']}}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.input_schema.schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Harsha.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser  \n",
    "chain.invoke({\n",
    "    \"context\": \"The name I was given was Harsha\",\n",
    "    \"question\": \"What is my name?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sriharsha/Desktop/Clg/RAG/local-model/.venv/lib/python3.11/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# using a vector database to convert all the pages of the pdf to embeddings and then use the embeddings to find the most similar text\n",
    "# we can later compare those embeddings with the embeddings of the prompt and the question to find the most similar text\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "# creating vector store from the pages in memory\n",
    "vectorstore = DocArrayInMemorySearch.from_documents(pages, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='2.1   Architectural View   \\nThe proposed architecture consists of two layers: a device layer and a fog layer; as \\nshown in Fig.  1. The devi ce layer consists of multiple EEG devices which are \\nindependent of each other. In the fog layer, heterogeneous fog devices are connected \\nto the FH.   \\nThe functions  of the device layer are  to: \\n\\uf0b7 Sense  brain signals  of patients using multiple EEG sensors  \\n\\uf0b7 Divide  the continuous raw EEG signal into chunks  \\n\\uf0b7 Transmit  the chunks as output files to the fog layer  \\nThe functions  of the fog layer are  to: \\n\\uf0b7 Receive the EEG data files from the device layer  \\n\\uf0b7 Select  one of the fog devices as FH  \\n\\uf0b7 Collaborative and distributed proces sing of the tasks among fog devices  \\n\\uf0b7 Acknowledge  the resp onses  \\n \\n                   \\n  \\nFig. 1. Proposed  2DP-FHS architecture .', metadata={'source': 'fog_computing_paper.pdf', 'page': 2}),\n",
       " Document(page_content='Case  II: If NSS consists of more than one non -dominated solution , then FH and the \\nAFH are selected based on the minimal distances from UP.  \\nCase III: For the chosen \\n  and \\n  values, there are  3 sub -cases  as listed below:  \\n\\uf0b7 If \\n , solution impact: Delay Minimized  \\n\\uf0b7 If \\n , solution impact: Performance Maximized  \\n\\uf0b7 If \\n , solution impact: Balanced  \\n3   Simulation and Result Analysis  \\nThe simulation  work  is carried out using Python v3.12 in MAC OS; having M1 Pro \\nprocessor and 16 GB RAM  assuming the EEG and the fog layer as 200m √ó 200m \\narea. Moreover , a synthetic fog database is created with 8  distinct  fog devices as given \\nin the Table 1. Further, Table 2 describes the synthetic EEG data generated for \\nprocessing and analysis.  \\n \\nTable 1.  Heterogeneous f og devices with  their configurations . \\n \\nFog ID \\n  (in GHz)  \\n  (in GHz)  RAM  (in GB)  MIPS  \\n1 1.43 1.43 4 9000  \\n2 1.5 1.5 4 12000  \\n3 1.4 1.9 8 9000  \\n4 1.1 2.6 4 8800  \\n5 1.8 2.84 8 12000  \\n6 1.8 3.23 6 15000  \\n7 2.5 3.4 4 20000  \\n8 2.6 3.8 8 12080  \\n \\n Table 2.  Synthetic EEG dataset . \\n \\nEEG No.  Channels  Sampling F requency  Files Data Volume  \\n1 32 150 Hz  10 6.9945 Mb  \\n2 16 170 Hz  4 5.24 Mb  \\n3 64 250 Hz  6 15.42 Mb  \\n4 32 230 Hz  5 7.95 Mb  \\n \\n   Further, in this section, th e authors have illustrated two different scenarios in \\nselecting FH and AFH  for NSS . Fig. 3 shows the placement of the devices with the \\npareto solutions where UP is different from RP. However, Fig. 4 shows a different \\nscenario where UP is same as RPs.', metadata={'source': 'fog_computing_paper.pdf', 'page': 7}),\n",
       " Document(page_content='computing focusing on minimizing delay and bandwidth.  Paper [6] uses FireFly \\noptimization for cost -reduction -based resource allocation and load balancing in  cloud \\nfog architecture.  Further, multiple heterogeneous fog devices participate in parallel \\nand distributed decision -making processes. Therefore, the optimal selection of fog \\nheads and fog resources is necessary  [7], [8], [9] . Many techniques are develope d by \\nthe researchers emphasizing the optimal selection methods for various applications, \\nbut there is a lack of developments in EEG healthcare systems. In this work, the \\nauthors have focused on the optimal fog head selection technique for EEG based \\nhealthc are systems using the Pareto Optimization [10].  \\n1.1   Motivation  and Contribution  \\nThe existing EEG healthcare systems are mostly cloud -dependent  [11]. The cloud \\nprovides major  services such as big data management, permanent storage , and heavy  \\nprocessing; b ut consumes high bandwidth and high latency which is unacceptable in \\nreal-time healthcare analysis  [12], [13] . Moreover, EEG devices are single -user \\nassistive devices  and, therefore need dedicated computing resources. To address the \\nabove challenges, fog c omputing is integrated with multiple EEG healthcare systems. \\nThe integration of fog computing supports real -time data analysis with minimum \\nlatency and faster response time  [14], [15] . Further, it supports scalability and \\nheterogeneity which helps in proce ssing huge volumes of EEG data in a distributed \\nmanner  [16]. The contributions in this paper are listed below:  \\ni) A two -layer architecture is proposed, where multiple EEG devices are merged in \\none platform to perform distributed computation and data analyt ics connecting with a \\ngroup of heterogeneous fog devices . \\nii) An optimal  Fog Head  (FH) and an Alternate Fog Head (AFH) are selected using \\ntwo-dimensional  Pareto  optimization undertaking multiple scenarios.  \\niii) Further delay analysis is performed in the fo g layer with a change in the number of \\nEEG devices and the number of fog devices.  \\n   The further sections are organized as follows: Section 2 describes the proposed \\nmethodology. Section 3 illustrates the simulation result. Finally, section 4 concludes \\nthe paper.  \\n2   Proposed Methodology  \\nIn this paper, the authors have proposed a multi -layer architecture where multiple \\nEEG devices collaborate with multiple fog devices through a fog head. In the real \\nscenario, a single fog device is not sufficient for process ing EEG data from multiple \\nEEG devices due to energy, storage , and computational constraints. Therefore, \\nmultiple fog devices having different configurations are considered for this work. \\nAlso, in this work, an optimal fog device among all the fog devices is selected which \\nis discussed further. The next subsection presents the proposed architectural view and \\nits functions.', metadata={'source': 'fog_computing_paper.pdf', 'page': 1}),\n",
       " Document(page_content='computing services, Engineering Applications of Artificial Intelligence, Volume 121, \\n105998, (2023) ISSN 0952 -1976 \\n8. Tao Han, Lijuan Zhang, Sandeep Pirbhulal, Wanqing Wu, Victor Hugo C. de \\nAlbuquerque, A novel cluster head selection technique for edge -computing based \\nIoMT systems, Computer Networks, Volume 158, (2019), Pages 114 -122, ISSN  \\n1389 -1286 \\n9. Devi, A., Kait, R., Ranga, V. Automated Cluster Head Selection in Fog -VANET \\nVia Machine Learning. In: Sharma, H., Shrivastava, V., Kumari Bharti, K., Wang, L. \\n(eds) Commun ication and Intelligent Systems . Lecture Notes in Networks and \\nSystems , vol 461. Springer, Singapore (2022 ) \\n10. Nyoman Gunantara | A review of multi -objective optimization: Methods and its \\napplications, Cogent Engineering, 5:1, (2018) 1502242  \\n11. X. Gu  et al., \"EEG -Based Brain -Computer Interfaces (BCIs): A Survey of Recent \\nStudies on Signal Sensing Technologies and Computational Intelligence Approaches \\nand Their Applications,\" in  IEEE/ACM Transactions on Computational Biology and \\nBioinformatic s, vol. 18, no. 5, (2021) pp.1645 -1666   \\n12. Dilip Kumar Sharma, Dhruva Sreenivasa C hakravarthi, Asmat Ara Shaikh, Alim \\nAl Ayub Ahmed, Sushma Jaiswal, Mohd Naved, The aspect of vast data management \\nproblem in healthcare sector and implementation of cloud computing technique, \\nMaterials Today: Proceedings, Volume 80, Part 3, (2023), Pages 3 805-3810, ISSN \\n2214 -7853  \\n13. Anjum, A.  et al. Big Data Analytics in Healthcare: A Cloud -Based Framework for \\nGenerating Insights. In: Antonopoulos, N., Gillam, L. (eds) Cloud Computing. \\nComputer Communications and Networks. Springer, Cham (2017 ) \\n14. Jain, R., Gupta, M., Nayyar, A., Sharma, N. Adoption of Fog Computing in \\nHealthcare 4.0. In: Tanwar, S. (eds) Fog Computing for Healthcare 4.0 Environments. \\nSignals and Communication Technology. Springer, Cham (2021 ) \\n15. Dubey, H.  et al. Fog Computing in Medical Internet -of-Things: Architecture, \\nImplementation, and Applications. In: Khan, S., Zomaya, A., Abbas, A. (eds) \\nHandbook of Large -Scale Distributed Computing in Smart Healthcare. Scalable \\nComputing and Communications. Springer, Cham (2017 ) \\n16. N. M. Gonzalez  et al., \"Fog computing: Data analytics and cloud distributed \\nprocessing on the network edges,\"  2016 35th International Conference of the Chilean \\nComputer Science Society (SCCC ), Valparaiso, Chile, (2016), pp. 1 -9.', metadata={'source': 'fog_computing_paper.pdf', 'page': 11})]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retriever is a component of langchain that is used to retrieve the most similar text / context based on the input\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever.invoke(\"Fog Computing\")\n",
    "#? retriever returns the 4 top documents that are most relevant to the retrieved term\n",
    "#? sorted in the order of importance\n",
    "#? this retriever is basically used to provide context to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fog computing is a distributed computing paradigm that involves processing data closer to the source of the data, rather than sending it to a centralized cloud or data center for processing. In contrast to traditional cloud computing, where data is sent to a remote server for processing, fog computing brings computing resources closer to the edge of the network, typically within a few kilometers of the data source. This can help reduce latency and improve real-time processing capabilities, making it particularly useful for applications that require fast processing times, such as IoT devices, autonomous vehicles, and smart cities.\\n\\nFog computing typically involves a distributed architecture with multiple nodes located at different points in the network, each node performing specific tasks and communicating with other nodes to achieve a common goal. This allows for more efficient use of resources and can help ensure that data is processed closer to where it is generated, reducing latency and improving overall system performance.\\n\\nSome key characteristics of fog computing include:\\n\\n1. Edge computing: Fog computing involves processing data closer to the edge of the network, typically at the network gateway or within a local area network (LAN).\\n2. Distributed architecture: Fog computing typically involves multiple nodes located at different points in the network, each node performing specific tasks and communicating with other nodes to achieve a common goal.\\n3. Real-time processing: Fog computing is designed for real-time processing of data, which is critical for applications such as autonomous vehicles, smart cities, and industrial IoT.\\n4. Decentralized data management: Fog computing allows for decentralized data management, reducing the need for a centralized data repository and improving data security and privacy.\\n5. Scalability: Fog computing is designed to scale horizontally by adding more nodes to the network, allowing it to handle increasing volumes of data and processing tasks.\\n\\nOverall, fog computing is an important technology that can help enable a range of innovative applications and use cases, particularly in areas where real-time processing and low latency are critical.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response from Llama2\n",
    "from operator import itemgetter\n",
    "chain = (\n",
    "  {\n",
    "    \"context\": itemgetter(\"question\") | retriever, #? the context is going to come from the retriever\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "  } | \n",
    "  prompt | model | parser\n",
    ")\n",
    "#? the retriever requires the question that is invoking the chain to provide context to the model\n",
    "chain.invoke({ \"question\": \"what is fog computing\" }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context provided, Fog Computing can be defined as a decentralized architecture that provides data processing and analytics closer to where it is generated, reducing latency and improving real-time decision-making. It involves multiple devices (M) such as EEG devices and N number of fog devices that process and analyze data in real-time, enabling faster and more efficient processing of data.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response from Llama3\n",
    "from operator import itemgetter\n",
    "chain = (\n",
    "  {\n",
    "    \"context\": itemgetter(\"question\") | retriever, #? the context is going to come from the retriever\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "  } | \n",
    "  prompt | model | parser\n",
    ")\n",
    "#? the retriever requires the question that is invoking the chain to provide context to the model\n",
    "chain.invoke({ \"question\": \"what is fog computing\" }) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the main objective of this work?\n",
      "Answer:  The main objective of this work is to propose a novel fog computing-based approach for EEG healthcare systems, which can efficiently process and analyze large volumes of EEG data in real-time. The authors aim to address the challenges of high latency and bandwidth consumption in traditional cloud-based EEG systems by leveraging the computing resources of multiple heterogeneous fog devices. Additionally, the authors aim to optimize the selection of fog heads and fog resources for optimal performance in EEG healthcare systems using Pareto optimization.\n",
      "\n",
      "Question:  What are the possible challenges in fog computing?\n",
      "Answer:  Based on the provided documents, some of the possible challenges in fog computing include:\n",
      "\n",
      "1. Data Management Problems: The vast amount of data generated by IoT devices and sensors can cause challenges in managing and processing the data in real-time. (Document 3, Page 5)\n",
      "2. Processor and Memory Limitations: Fog devices have limited processor and memory capabilities, which can impact their ability to process and analyze large amounts of data. (Document 4, Page 10)\n",
      "3. Clock Speed and MIPS: The computational efficiency of fog devices is dependent on their clock speed and MIPS, which can result in slower processing times for complex tasks. (Document 5, Page 5)\n",
      "4. Failure and Reliability: Ensuring the uninterrupted operation of EEG tasks in the fog layer requires the selection of an optimal Fog Head (FH) and Alternate Fog Head (AFH) to handle failures. (Document 6, Page 8)\n",
      "5. Tradeoff between FDI and FPI: The tradeoff function for selecting the optimal FH and AFH is dependent on the fitness score based on the tradeoff between FDI and FPI, which can be challenging to calculate. (Document 7, Page 11)\n",
      "6. Security Concerns: Fog computing raises security concerns as it involves processing and analyzing data at the edge of the network, making it vulnerable to attacks. (Document 8, Page 12)\n",
      "7. Interoperability: Ensuring seamless integration between fog devices and other components in the network can be challenging due to differences in hardware and software architectures. (Document 9, Page 13)\n",
      "8. Power Consumption: Fog devices have limited power capacity, which can result in reduced processing times for complex tasks and increased energy consumption. (Document 10, Page 14)\n",
      "\n",
      "These challenges highlight the need for careful consideration and optimization of fog computing systems to ensure their efficient operation and reliability.\n",
      "\n",
      "Question:  What are the possible solutions to the challenges in fog computing?\n",
      "Answer:  Based on the provided document, there are several possible solutions to the challenges in fog computing:\n",
      "\n",
      "1. Selection of FH and AFH: The paper proposes a novel approach for selecting an optimal Fog Head (FH) and Alternate Fog Head (AFH) to ensure uninterrupted operation in the fog layer. This solution addresses the challenge of ensuring smooth operation in the fog layer by selecting an optimal FH and AFH based on fitness scores calculated using a tradeoff function.\n",
      "2. Optimal allocation of resources: The paper discusses the importance of optimally allocating resources, such as RAM and processor components, to achieve efficient computing in the fog layer. This solution addresses the challenge of computational efficiency by optimizing resource allocation.\n",
      "3. Use of machine learning algorithms: The paper proposes using machine learning algorithms to predict and mitigate failures in the fog layer. This solution addresses the challenge of failure prediction and management by leveraging machine learning techniques.\n",
      "4. Distributed computing: The paper suggests using distributed computing to improve the efficiency of computing tasks in the fog layer. This solution addresses the challenge of computational efficiency by distributing computing tasks across multiple nodes or devices.\n",
      "5. Adaptive resource allocation: The paper proposes an adaptive resource allocation approach that dynamically adjusts the allocation of resources based on changing conditions in the fog layer. This solution addresses the challenge of ensuring optimal resource allocation by adapting to changing conditions.\n",
      "6. Fog device management: The paper discusses the importance of managing fog devices to ensure their proper functioning and avoid failures. This solution addresses the challenge of managing fog devices by implementing a novel approach for fog device management.\n",
      "7. Energy efficiency: The paper highlights the importance of energy efficiency in fog computing and proposes several solutions to improve it, such as reducing the number of nodes or devices, using low-power devices, and optimizing resource allocation. This solution addresses the challenge of energy efficiency by minimizing the power consumption of fog computing systems.\n",
      "8. Security: The paper acknowledges the security challenges in fog computing and proposes several solutions to address them, such as implementing secure communication protocols, using encryption techniques, and ensuring proper authentication and authorization mechanisms. This solution addresses the challenge of security by ensuring the confidentiality, integrity, and availability of data and systems in the fog layer.\n",
      "\n",
      "These are some of the possible solutions to the challenges in fog computing based on the provided document. However, it is essential to note that the specific solution will depend on the context and requirements of the fog computing system.\n",
      "\n",
      "Question:  What is the future scope of fog computing?\n",
      "Answer:  Based on the provided documents, fog computing has a wide range of potential applications and can be applied to various fields such as healthcare, finance, transportation, and more. The future scope of fog computing includes:\n",
      "\n",
      "1. Increased use in IoT devices: As more devices become connected to the internet, fog computing will play a crucial role in managing and processing data from these devices.\n",
      "2. Expansion into new industries: Fog computing has the potential to be applied to industries such as agriculture, logistics, and energy management.\n",
      "3. Improved security: With the increasing use of fog computing, there is a growing need for improved security measures to protect data and applications in the fog layer.\n",
      "4. Integration with edge AI: Fog computing will be integrated with edge AI to enable more complex processing and decision-making at the edge of the network.\n",
      "5. Enhanced privacy and compliance: As fog computing gains more traction, there will be a greater need for enhanced privacy and compliance measures to protect sensitive data and applications.\n",
      "6. More efficient use of resources: Fog computing can help optimize resource usage by analyzing data closer to the source and reducing the amount of data that needs to be transmitted to the cloud or other remote locations.\n",
      "7. Better performance: Fog computing can provide better performance and faster response times due to the reduced distance between the data source and the processing location.\n",
      "8. Increased scalability: As more devices connect to the fog layer, it will become increasingly important to ensure that the fog computing infrastructure can scale to accommodate this growth.\n",
      "9. Improved real-time analytics: Fog computing can provide real-time analytics and insights by processing data closer to the source, reducing latency and improving decision-making.\n",
      "10. Enhanced user experience: Fog computing can help create a more seamless and responsive user experience by reducing latency and improving the performance of applications and services.\n",
      "\n",
      "In summary, the future scope of fog computing is vast and exciting, with potential applications in various industries and improvements in security, efficiency, scalability, and performance.\n",
      "\n",
      "Question:  How is fog computing better than cloud computing in solving their problem?\n",
      "Answer:  Fog computing is considered better than cloud computing in solving the problem of real-time EEG data analysis in healthcare for several reasons:\n",
      "\n",
      "1. **Location and connectivity**: Fog computing is more location-independent as it can be deployed closer to the edge devices (EEG sensors) compared to cloud computing, which requires a longer network path. This reduction in latency and increased connectivity makes fog computing better suited for real-time EEG data analysis.\n",
      "2. **Computational resources**: Fog computing offers more computational resources than cloud computing, as it can utilize the processing power of multiple fog devices. This is particularly useful when dealing with large volumes of EEG data, which requires significant computational resources.\n",
      "3. **Data privacy and security**: Fog computing is considered more secure and private compared to cloud computing due to its decentralized nature. The EEG data remains within the local fog network, reducing the risk of unauthorized access or data breaches.\n",
      "4. **Cost-effectiveness**: Fog computing can be more cost-effective than cloud computing as it eliminates the need for expensive and complex infrastructure, such as data centers and high-performance servers. This is particularly important in healthcare where budget constraints are common.\n",
      "5. **Scalability**: Fog computing offers better scalability compared to cloud computing as it can handle a large number of devices and applications without affecting performance. This makes it ideal for real-time EEG data analysis, which requires processing large amounts of data from multiple sources.\n",
      "6. **Real-time processing**: Fog computing is designed for real-time processing, making it better suited for EEG data analysis. The reduced latency and faster response times ensure that the analysis is performed in a timely manner, which is crucial in healthcare applications.\n",
      "7. **Heterogeneity management**: Fog computing can handle heterogeneous devices and applications more effectively than cloud computing. This is particularly important in healthcare where diverse EEG sensors and devices are used to collect data.\n",
      "8. **Flexibility**: Fog computing offers greater flexibility compared to cloud computing as it allows for the integration of multiple technologies and systems, such as IoT devices, drones, and autonomous vehicles. This is important in healthcare where diverse devices and systems are used to collect data and provide insights.\n",
      "9. **Less dependence on internet**: Fog computing reduces the dependence on high-speed internet connectivity compared to cloud computing, which makes it more reliable in areas with limited internet connectivity.\n",
      "10. **More control over resources**: With fog computing, organizations have more control over their computing resources, as they can manage and allocate resources more effectively compared to cloud computing. This is particularly important in healthcare where resource management is critical.\n",
      "\n",
      "In summary, fog computing offers several advantages over cloud computing for real-time EEG data analysis in healthcare, including reduced latency, increased security and privacy, cost-effectiveness, scalability, flexibility, reliance on internet connectivity, and control over resources.\n",
      "\n",
      "Question:  What problem are the authors trying to solve?\n",
      "Answer:  The authors are trying to solve the problem of selecting an optimal fog head (FH) for smooth operation of EEG tasks in the fog layer, while ensuring uninterrupted operation in case of failure. They propose a two-dimensional Pareto optimization technique to separate dominant solution space (DSS) and non-dominated solution space (NSS), and then select the optimal FH based on the number of fog devices and their configurations. Additionally, they consider an alternate fog head (AFH) to take control in case of failure.\n",
      "\n",
      "Question:  What is the main contribution of this work?\n",
      "Answer:  The main contribution of this work is the proposed technique for selecting an optimal Fog Head (FH) and Alternate Fog Head (AFH) for smooth operation of EEG tasks in a fog computing environment. The proposed technique uses a multi-objective optimization approach to separate Dominated Solution Space (DSS) and Non-dominated Solution Space (NSS), and then selects the best solution from NSS based on a tradeoff function. The main contributions of this work can be summarized as follows:\n",
      "\n",
      "1. Proposal of a new technique for selecting an optimal FH and AFH in a fog computing environment, which ensures smooth operation of EEG tasks and uninterrupted fog layer operation.\n",
      "2. Use of a multi-objective optimization approach to separate DSS and NSS, which helps to identify the best solution that balances the conflicting objectives of FDI and FPI.\n",
      "3. Calculation of a tradeoff function based on the relative weight of FDI and FPI, which helps to select the best solution from NSS.\n",
      "4. Presentation of the selection process through diagrams and tables, which provides clarity and easy understanding of the proposed technique.\n",
      "5. Evaluation of the proposed technique through simulations, which demonstrates its effectiveness in selecting an optimal FH and AFH for smooth operation of EEG tasks in a fog computing environment.\n",
      "\n",
      "Overall, the main contribution of this work is to provide a novel approach for selecting an optimal FH and AFH in a fog computing environment, which can help to ensure efficient and reliable operation of EEG tasks in a fog layer.\n",
      "\n",
      "Question:  What are the limitations of this work?\n",
      "Answer:  The limitations of this work include:\n",
      "\n",
      "1. Limited scope: The work focuses only on EEG healthcare systems and does not consider other types of applications that can benefit from fog computing.\n",
      "2. Simplistic optimization: The authors use a simplistic Pareto optimization approach to select the optimal fog head, which may not take into account more complex optimization problems.\n",
      "3. Limited consideration of fog device heterogeneity: The authors assume that all fog devices have the same configuration, which is unlikely in practical scenarios where fog devices may have different hardware and software configurations.\n",
      "4. Lack of consideration of security and privacy: The work does not provide any discussion on the security and privacy implications of using fog computing for EEG healthcare systems.\n",
      "5. Limited scalability: The authors do not consider the impact of scaling up the number of EEG devices or fog devices on the performance of the proposed approach.\n",
      "6. Lack of real-world validation: The work does not provide any real-world validation of the proposed approach, which limits its applicability in practical scenarios.\n",
      "7. Limited comparison with other approaches: The authors do not provide a comprehensive comparison of their proposed approach with other fog computing-based solutions for EEG healthcare systems, which limits its appreciation.\n",
      "8. Limited discussion on potential applications: The work does not provide a detailed discussion on the potential applications of the proposed approach beyond EEG healthcare systems, which limits its scope.\n",
      "\n",
      "Question:  What are the possible future directions of this work?\n",
      "Answer:  Based on the context provided, there are several potential future directions for this work on Fog computing for EEG tasks:\n",
      "\n",
      "1. Exploring new optimization techniques: The current work uses a simple trade-off function to optimize the selection of FH and AFH. Future works could investigate more advanced optimization techniques, such as multi-objective optimization or evolutionary algorithms, to improve the selection process.\n",
      "2. Investigating hybrid approaches: The current work focuses on using a single fog device for EEG tasks. Future works could explore hybrid approaches that combine fog and cloud computing, or use different types of fog devices (e.g., edge devices, IoT devices) for EEG tasks.\n",
      "3. Expanding the scope to other applications: While the current work focuses on EEG tasks, future works could investigate the applicability of Fog computing to other brain-related applications, such as medical imaging or brain-computer interfaces.\n",
      "4. Investigating real-world deployments: Future works could investigate real-world deployments of Fog computing for EEG tasks, including evaluating performance, energy consumption, and scalability. This would help validate the theoretical results and provide insights into practical deployment scenarios.\n",
      "5. Exploring security and privacy aspects: With the increasing use of Fog computing, there is a growing concern about security and privacy. Future works could investigate the security and privacy implications of using Fog computing for EEG tasks and develop mitigation strategies to address these concerns.\n",
      "6. Investigating dynamic and adaptive management: The current work assumes a static selection of FH and AFH. Future works could investigate dynamic and adaptive management techniques that can adjust the selection of FH and AFH based on changing conditions, such as changes in user preferences or environmental factors.\n",
      "7. Exploring federated learning frameworks: Future works could investigate using federated learning frameworks to enable multiple fog devices to collaboratively perform EEG tasks while preserving privacy and security. This would provide a more scalable and efficient solution for large-scale EEG tasks.\n",
      "\n",
      "Question:  What is the significance of this work?\n",
      "Answer:  The significance of this work lies in its novel approach to solving the problem of selecting an optimal fog head for EEG-based healthcare systems. The authors propose a multi-layer architecture that combines multiple EEG devices with multiple heterogeneous fog devices, which enables real-time data analysis and processing with minimal latency and faster response time.\n",
      "\n",
      "The proposed methodology uses two-dimensional Pareto optimization to select the optimal fog head and an alternate fog head, taking into account multiple scenarios and their associated uncertainties. This approach ensures that the selected fog heads are not only efficient but also robust in the face of uncertainty.\n",
      "\n",
      "Furthermore, the authors conduct a comprehensive analysis of the impact of varying numbers of EEG devices and fog devices on the delay in the fog layer, providing valuable insights into the scalability and heterogeneity of the proposed architecture.\n",
      "\n",
      "The contributions of this work can be summarized as follows:\n",
      "\n",
      "1. Proposal of a multi-layer architecture that combines EEG devices and heterogeneous fog devices for real-time data analysis and processing.\n",
      "2. Development of a novel optimization methodology based on two-dimensional Pareto optimization to select the optimal fog head and an alternate fog head.\n",
      "3. Analysis of the impact of varying numbers of EEG devices and fog devices on the delay in the fog layer, providing insights into the scalability and heterogeneity of the proposed architecture.\n",
      "\n",
      "Overall, this work has significant implications for the development of EEG-based healthcare systems, as it provides a novel and robust approach to selecting optimal fog heads that can handle complex data processing tasks with minimal latency and faster response time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# response from Llama2\n",
    "questions = [\n",
    "  \"What is the main objective of this work?\",\n",
    "  \"What are the possible challenges in fog computing?\",\n",
    "  \"What are the possible solutions to the challenges in fog computing?\",\n",
    "  \"What is the future scope of fog computing?\",\n",
    "  \"How is fog computing better than cloud computing in solving their problem?\",\n",
    "  \"What problem are the authors trying to solve?\",\n",
    "  \"What is the main contribution of this work?\",\n",
    "  \"What are the limitations of this work?\",\n",
    "  \"What are the possible future directions of this work?\",\n",
    "  \"What is the significance of this work?\",\n",
    "]\n",
    "\n",
    "for question in questions: \n",
    "  print(\"Question: \", question)\n",
    "  print(f\"Answer: \", chain.invoke({ 'question': question }))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question:  What is the main objective of this work?\n",
      "Answer:  The main objective of this work is to propose a methodology for optimal fog head selection in an EEG healthcare system using Pareto optimization, with the goal of minimizing delay and bandwidth while ensuring uninterrupted operation.\n",
      "\n",
      "Question:  What are the possible challenges in fog computing?\n",
      "Answer:  I don't know. The provided context does not mention specific challenges in fog computing. It appears to be a paper about fog computing, discussing topics such as synthetic fog dataset, selection of fog head and alternate fog head, and average delay analysis with increase in number of EEG devices and fog devices. To answer the question, I would need more information or a different context.\n",
      "\n",
      "Question:  What are the possible solutions to the challenges in fog computing?\n",
      "Answer:  I don't know. The provided context appears to be a research paper on fog computing, discussing various aspects such as edge computing, IoT systems, cluster head selection, and workflow. However, it does not explicitly discuss potential solutions to challenges in fog computing. To answer this question accurately, I would need more information about the specific challenges being addressed or additional context from the paper.\n",
      "\n",
      "Question:  What is the future scope of fog computing?\n",
      "Answer:  I don't know. The provided context does not mention anything about the future scope of fog computing. It appears to be a research paper discussing various aspects of fog computing, such as cluster head selection and workflow, but it doesn't provide any information on the future direction or potential applications of fog computing.\n",
      "\n",
      "Question:  How is fog computing better than cloud computing in solving their problem?\n",
      "Answer:  Based on the provided context, fog computing is better than cloud computing in solving the problem of EEG healthcare systems because it provides:\n",
      "\n",
      "* Real-time data analysis with minimum latency and faster response time\n",
      "* Scalability and heterogeneity, which helps in processing huge volumes of EEG data in a distributed manner\n",
      "* Localized computation and data analytics, connecting multiple EEG devices to a group of heterogeneous fog devices\n",
      "\n",
      "These advantages make fog computing more suitable for real-time healthcare analysis compared to cloud computing.\n",
      "\n",
      "Question:  What problem are the authors trying to solve?\n",
      "Answer:  The authors are trying to optimize the selection of fog heads and fog resources in a multi-layer architecture for EEG healthcare systems, while minimizing delay and bandwidth.\n",
      "\n",
      "Question:  What is the main contribution of this work?\n",
      "Answer:  I don't know. The context provided seems to be a research paper on fog computing and edge computing, but it doesn't explicitly state the main contribution of the work.\n",
      "\n",
      "Question:  What are the limitations of this work?\n",
      "Answer:  Based on the provided context, there is no direct answer to the question about the limitations of this work. However, I can provide some possible applications and implications that might be relevant:\n",
      "\n",
      "* The paper focuses on optimizing fog head selection for EEG-based healthcare systems using Pareto optimization. This suggests that the work assumes a specific context and may not generalize well to other domains or scenarios.\n",
      "* The authors mention that there is a lack of developments in EEG healthcare systems, which implies that the field is still evolving, and this work might be addressing some of the existing gaps.\n",
      "* The paper highlights the challenges of real-time data analysis and processing huge volumes of EEG data. This suggests that the limitations might lie in the scalability and adaptability of the proposed approach to different scenarios or datasets.\n",
      "\n",
      "To answer your question more directly, I would need further information on what specific limitations you are looking for (e.g., computational complexity, applicability to other domains, etc.). If you could provide more context or clarify what you mean by \"limitations,\" I'd be happy to try and address your question.\n",
      "\n",
      "Question:  What are the possible future directions of this work?\n",
      "Answer:  I don't know.\n",
      "\n",
      "Question:  What is the significance of this work?\n",
      "Answer:  The significance of this work is that it proposes a multi-layer architecture where multiple EEG devices collaborate with multiple fog devices through a fog head, which enables real-time data analysis with minimum latency and faster response time. Additionally, it optimizes Fog Head (FH) selection using two-dimensional Pareto optimization, addressing the challenges of existing EEG healthcare systems that are mostly cloud-dependent and require high bandwidth and low latency.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# response from Llama3\n",
    "questions = [\n",
    "  \"What is the main objective of this work?\",\n",
    "  \"What are the possible challenges in fog computing?\",\n",
    "  \"What are the possible solutions to the challenges in fog computing?\",\n",
    "  \"What is the future scope of fog computing?\",\n",
    "  \"How is fog computing better than cloud computing in solving their problem?\",\n",
    "  \"What problem are the authors trying to solve?\",\n",
    "  \"What is the main contribution of this work?\",\n",
    "  \"What are the limitations of this work?\",\n",
    "  \"What are the possible future directions of this work?\",\n",
    "  \"What is the significance of this work?\",\n",
    "]\n",
    "\n",
    "for question in questions: \n",
    "  print(\"Question: \", question)\n",
    "  print(f\"Answer: \", chain.invoke({ 'question': question }))\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fog computing is better than cloud computing in solving the problem of EEG healthcare systems for several reasons:\n",
      "\n",
      "1. Latency: Fog computing reduces latency by processing data closer to the source, which is critical in real-time healthcare analysis. Cloud computing can take longer to process data due to its distance from the source and higher network latency.\n",
      "2. Scalability: Fog computing supports scalability better than cloud computing as it can handle a large volume of data from multiple EEG devices. In contrast, cloud computing can become overwhelmed with too much data, leading to slower processing times.\n",
      "3. Heterogeneity: Fog computing supports heterogeneity by allowing for multiple fog devices with different configurations to process data in parallel and distributed decision-making processes. Cloud computing often lacks this level of flexibility and customization.\n",
      "4. Cost-effectiveness: Fog computing can be more cost-effective than cloud computing as it leverages existing infrastructure, reducing the need for expensive hardware upgrades or new data centers.\n",
      "5. Real-time processing: Fog computing is designed to handle real-time data processing and analytics, which is critical in healthcare applications where decisions are made quickly based on patient data. Cloud computing may not be able to keep up with these requirements due to its distance from the source and higher latency.\n",
      "6. Privacy and security: Fog computing can provide better privacy and security for sensitive medical data as it processes data closer to the source, reducing the risk of data breaches or cyber attacks over long-distance networks.\n",
      "7. Resource optimization: Fog computing optimizes resources better than cloud computing by selectively allocating resources based on the specific needs of each EEG device, leading to more efficient use of resources and reduced costs.\n",
      "8. Distributed decision-making: Fog computing supports distributed decision-making processes better than cloud computing as it allows for multiple fog devices to participate in parallel processing and decision-making. This can lead to faster and more accurate analysis and diagnosis in healthcare applications.\n",
      "9. Better integration with existing systems: Fog computing integrates well with existing healthcare systems, such as hospitals' electronic medical record (EMR) systems, laboratory information systems, radiology systems, etc., due to its close proximity to the source data and faster processing times.\n",
      "10. Better adaptability: Fog computing is more adaptable than cloud computing as it can be easily scaled up or down depending on changing healthcare needs, whereas cloud computing often requires significant infrastructure changes to accommodate changes in workload or demand."
     ]
    }
   ],
   "source": [
    "# response from Llama2\n",
    "for s in chain.stream({\"question\": \"How is fog computing better than cloud computing in solving their problem?\"}):\n",
    "  print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, fog computing is better than cloud computing in solving the problem of real-time healthcare analysis with minimum latency and faster response time. This is because fog computing provides:\n",
      "\n",
      "* Real-time data analysis with minimum latency\n",
      "* Faster response time\n",
      "* Scalability and heterogeneity, which helps in processing huge volumes of EEG data in a distributed manner\n",
      "\n",
      "These advantages are not explicitly mentioned as being better than cloud computing, but they imply that fog computing can provide a more suitable solution for real-time healthcare analysis compared to cloud computing."
     ]
    }
   ],
   "source": [
    "# response from Llama3\n",
    "for s in chain.stream({\"question\": \"How is fog computing better than cloud computing in solving their problem?\"}):\n",
    "  print(s, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
